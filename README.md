# LSTM-and-Transformer-like-network

Implementation of LST recurrent network architecture. It includes only one layer, while stacked LSTM implementation is possible.  In second part a simple Transformer-like network is implemented with simple scaled dot product attention and masked multi-head attention. Both implementations are incredibly simple and could be useful to beginners.
